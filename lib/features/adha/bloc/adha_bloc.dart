import 'package:flutter/foundation.dart';
import 'package:flutter_bloc/flutter_bloc.dart';
import 'package:uuid/uuid.dart';
import 'dart:async';
import '../repositories/adha_repository.dart';
import '../../auth/repositories/auth_repository.dart'; // Corrected path
import '../../dashboard/repositories/operation_journal_repository.dart'; // Corrected path
import '../../auth/models/user.dart'; // For User model
import '../services/audio_streaming_service.dart'
    as audio_service; // Pour le service audio
import '../services/adha_stream_service.dart'; // Pour le service de streaming
import '../models/adha_stream_models.dart'; // Pour les mod√®les de streaming
// For OperationJournalEntry model

import 'adha_event.dart';
import 'adha_state.dart';
import '../models/adha_message.dart';
import '../models/adha_context_info.dart';
import '../../../core/services/business_context_service.dart';

/// BLoC pour g√©rer l'interaction avec l'assistant Adha
class AdhaBloc extends Bloc<AdhaEvent, AdhaState> {
  final AdhaRepository adhaRepository;
  final AuthRepository authRepository;
  final OperationJournalRepository operationJournalRepository;
  final audio_service.AudioStreamingService _audioStreamingService;
  final AdhaStreamService _streamService; // Service de streaming
  final _uuid = const Uuid();
  String? _currentlyActiveConversationId; // Added to track active conversation

  // Subscriptions pour les streams audio
  StreamSubscription? _audioConnectionSubscription;
  StreamSubscription? _audioLevelSubscription;
  StreamSubscription? _isRecordingSubscription;
  StreamSubscription? _isPlayingSubscription;

  // Subscriptions pour le streaming de r√©ponses
  StreamSubscription<AdhaStreamChunkEvent>? _streamChunkSubscription;
  StreamSubscription<AdhaStreamConnectionState>? _streamConnectionSubscription;

  // Buffer pour accumuler le contenu de streaming
  final StringBuffer _accumulatedStreamContent = StringBuffer();
  String? _currentStreamingRequestId;

  AdhaBloc({
    required this.adhaRepository,
    required this.authRepository,
    required this.operationJournalRepository,
    audio_service.AudioStreamingService? audioStreamingService,
    AdhaStreamService? streamService,
  }) : _audioStreamingService =
           audioStreamingService ?? audio_service.AudioStreamingService(),
       _streamService = streamService ?? AdhaStreamService(),
       super(const AdhaInitial()) {
    _currentlyActiveConversationId = null; // Explicitly null at start

    // √âv√©nements existants
    on<SendMessage>(_onSendMessage);
    on<LoadConversations>(_onLoadConversations);
    on<LoadConversation>(_onLoadConversation);
    on<NewConversation>(_onNewConversation);
    on<DeleteConversation>(_onDeleteConversation);
    on<StartVoiceRecognition>(_onStartVoiceRecognition);
    on<StopVoiceRecognition>(_onStopVoiceRecognition);
    on<EditMessage>(_onEditMessage);

    // Nouveaux √©v√©nements audio
    on<StartAudioSession>(_onStartAudioSession);
    on<EndAudioSession>(_onEndAudioSession);
    on<ToggleRecording>(_onToggleRecording);
    on<InterruptAdha>(_onInterruptAdha);
    on<SetAudioVolume>(_onSetAudioVolume);
    on<AudioStateUpdate>(_onAudioStateUpdate);

    // √âv√©nements de streaming (Janvier 2026)
    on<ConnectToStreamService>(_onConnectToStreamService);
    on<DisconnectFromStreamService>(_onDisconnectFromStreamService);
    on<SendStreamingMessage>(_onSendStreamingMessage);
    on<StreamChunkReceived>(_onStreamChunkReceived);
    on<StreamCompleted>(_onStreamCompleted);
    on<StreamError>(_onStreamError);
    on<CancelStreaming>(_onCancelStreaming);

    // √âv√©nements de gestion de session
    on<ClearCurrentConversation>(_onClearCurrentConversation);
    on<InitializeForUser>(_onInitializeForUser);

    // Initialiser les listeners pour le service audio
    _initAudioListeners();

    // Initialiser les listeners pour le streaming
    _initStreamListeners();
  }

  /// Map audio service connection state to BLoC state
  AudioConnectionState _mapServiceToStateConnectionState(
    audio_service.AudioConnectionState serviceState,
  ) {
    switch (serviceState) {
      case audio_service.AudioConnectionState.disconnected:
        return AudioConnectionState.disconnected;
      case audio_service.AudioConnectionState.connecting:
        return AudioConnectionState.connecting;
      case audio_service.AudioConnectionState.connected:
        return AudioConnectionState.connected;
      case audio_service.AudioConnectionState.ready:
        return AudioConnectionState.ready;
      case audio_service.AudioConnectionState.error:
        return AudioConnectionState.error;
    }
  }

  // Helper to build AdhaContextInfo with the new structured models
  Future<AdhaContextInfo> _buildContextInfo(
    AdhaInteractionType interactionType, {
    String? sourceIdentifier,
    Map<String, dynamic>? interactionData,
    String?
    conversationId, // Optional: to determine if it's a follow-up if not explicitly set
  }) async {
    debugPrint(
      '[AdhaBloc] _buildContextInfo: interactionType=$interactionType',
    );
    debugPrint(
      '[AdhaBloc] _buildContextInfo: sourceIdentifier=$sourceIdentifier',
    );
    debugPrint('[AdhaBloc] _buildContextInfo: conversationId=$conversationId');

    // 1. Fetch Business Profile
    AdhaBusinessProfile businessProfile;
    try {
      final User? currentUser = await authRepository.getCurrentUser();
      debugPrint(
        '[AdhaBloc] _buildContextInfo: currentUser=${currentUser?.name}',
      );
      debugPrint(
        '[AdhaBloc] _buildContextInfo: currentUser.companyName=${currentUser?.companyName}',
      );
      debugPrint(
        '[AdhaBloc] _buildContextInfo: currentUser.companyId=${currentUser?.companyId}',
      );
      if (currentUser != null) {
        businessProfile = AdhaBusinessProfile(
          name: currentUser.companyName ?? 'Entreprise',
          sector: currentUser.businessSector,
          address: currentUser.companyLocation,
          additionalInfo: {
            'rccmNumber': currentUser.rccmNumber,
            'contactName': currentUser.name,
            'contactEmail': currentUser.email,
            'contactPhone': currentUser.phone,
          },
        );
      } else {
        businessProfile = const AdhaBusinessProfile(
          name: 'Wanzo Demo Business (Default)',
          sector: 'N/A',
        );
      }
    } catch (e) {
      debugPrint('Error fetching business profile for Adha context: $e');
      businessProfile = const AdhaBusinessProfile(
        name: 'Error Fetching Profile',
        sector: 'Error',
      );
    }

    // 2. Fetch Operation Journal Summary
    AdhaOperationJournalSummary operationJournalSummary;
    try {
      final recentEntries = await operationJournalRepository.getRecentEntries(
        limit: 5,
      );

      // Convertir les entr√©es du journal en AdhaOperationJournalEntry
      final adhaEntries =
          recentEntries
              .map(
                (entry) => AdhaOperationJournalEntry(
                  timestamp:
                      entry['timestamp']?.toString() ??
                      DateTime.now().toIso8601String(),
                  description: entry['description']?.toString() ?? '',
                  operationType:
                      entry['operationType']?.toString() ?? 'UNKNOWN',
                  details: entry['details'] as Map<String, dynamic>?,
                ),
              )
              .toList();

      operationJournalSummary = AdhaOperationJournalSummary(
        recentEntries: adhaEntries,
      );
    } catch (e) {
      debugPrint(
        'Error fetching operation journal summary for Adha context: $e',
      );
      operationJournalSummary = const AdhaOperationJournalSummary(
        recentEntries: [],
      );
    }

    final baseContext = AdhaBaseContext(
      operationJournalSummary: operationJournalSummary,
      businessProfile: businessProfile,
    );

    debugPrint(
      '[AdhaBloc] _buildContextInfo: businessProfile.name=${businessProfile.name}',
    );
    debugPrint(
      '[AdhaBloc] _buildContextInfo: operationJournalSummary.recentEntries.length=${operationJournalSummary.recentEntries.length}',
    );

    // D√©terminer le type d'interaction final
    AdhaInteractionType finalInteractionType = interactionType;
    if (conversationId != null &&
        interactionType != AdhaInteractionType.genericCardAnalysis) {
      finalInteractionType = AdhaInteractionType.followUp;
    }

    debugPrint(
      '[AdhaBloc] _buildContextInfo: finalInteractionType=$finalInteractionType',
    );

    final interactionContext = AdhaInteractionContext(
      interactionType: finalInteractionType,
      sourceIdentifier: sourceIdentifier,
      interactionData: interactionData,
    );

    final contextInfo = AdhaContextInfo(
      baseContext: baseContext,
      interactionContext: interactionContext,
    );

    // Log the final context JSON
    debugPrint('[AdhaBloc] _buildContextInfo: FINAL CONTEXT JSON:');
    debugPrint('[AdhaBloc] ${contextInfo.toJson()}');

    return contextInfo;
  }

  /// G√®re l'envoi d'un message √† Adha
  Future<void> _onSendMessage(
    SendMessage event,
    Emitter<AdhaState> emit,
  ) async {
    AdhaConversation currentConversation;
    AdhaContextInfo contextInfoForApi;
    AdhaConversationActive? previousState =
        state is AdhaConversationActive
            ? (state as AdhaConversationActive)
            : null;

    // D√©terminer si c'est une nouvelle conversation ou une existante
    // NOUVEAU (Janvier 2026): Le frontend g√©n√®re toujours le conversationId
    // pour permettre une meilleure tra√ßabilit√© et coh√©rence avec le mode streaming.
    bool isNewConversation = false;
    String? conversationIdForApi;

    if (state is AdhaConversationActive) {
      final currentState = state as AdhaConversationActive;
      currentConversation = currentState.conversation;
      conversationIdForApi = currentConversation.id; // Conversation existante
      contextInfoForApi = await _buildContextInfo(
        event.contextInfo?.interactionContext.interactionType ??
            AdhaInteractionType.followUp,
        sourceIdentifier:
            event.contextInfo?.interactionContext.sourceIdentifier,
        interactionData: event.contextInfo?.interactionContext.interactionData,
        conversationId: currentConversation.id,
      );
    } else {
      if (event.contextInfo == null) {
        emit(
          const AdhaError(
            "ContextInfo est requis pour d√©marrer une nouvelle conversation.",
          ),
        );
        return;
      }
      isNewConversation = true;
      // NOUVEAU: Le frontend g√©n√®re le conversationId (UUID)
      // et l'envoie au backend pour coh√©rence avec le mode streaming
      final clientGeneratedConversationId = _uuid.v4();
      conversationIdForApi = clientGeneratedConversationId;
      debugPrint(
        '[AdhaBloc] üÜï SendMessage - ID g√©n√©r√© c√¥t√© client: $clientGeneratedConversationId',
      );
      currentConversation = AdhaConversation(
        id: clientGeneratedConversationId,
        title: _generateConversationTitle(event.message),
        createdAt: DateTime.now(),
        updatedAt: DateTime.now(),
        messages: [],
      );
      contextInfoForApi = await _buildContextInfo(
        event.contextInfo!.interactionContext.interactionType,
        sourceIdentifier:
            event.contextInfo!.interactionContext.sourceIdentifier,
        interactionData: event.contextInfo!.interactionContext.interactionData,
        conversationId: clientGeneratedConversationId,
      );
    }

    final userMessage = AdhaMessage(
      id: _uuid.v4(),
      content: event.message,
      timestamp: DateTime.now(),
      sender: AdhaMessageSender.user,
    );

    final updatedMessages = List<AdhaMessage>.from(currentConversation.messages)
      ..add(userMessage);
    final updatedConversationWithUserMsg = currentConversation.copyWith(
      messages: updatedMessages,
      updatedAt: DateTime.now(),
    );

    emit(
      AdhaConversationActive(
        conversation: updatedConversationWithUserMsg,
        isProcessing: true,
        isVoiceActive: previousState?.isVoiceActive ?? false,
      ),
    );

    try {
      // Envoyer au backend avec le conversationId g√©n√©r√© c√¥t√© client
      final response = await adhaRepository.sendMessage(
        conversationId: conversationIdForApi, // ID g√©n√©r√© c√¥t√© client
        message: event.message,
        contextInfo: contextInfoForApi,
      );

      // V√©rifier si le backend a utilis√© l'ID fourni (nouveau comportement)
      // ou s'il a g√©n√©r√© un nouvel ID (ancien comportement - compatibilit√©)
      if (isNewConversation &&
          response.conversationId.isNotEmpty &&
          response.conversationId != conversationIdForApi) {
        debugPrint(
          '[AdhaBloc] ‚ö†Ô∏è Backend a retourn√© un ID diff√©rent: ${response.conversationId} vs $conversationIdForApi',
        );
        currentConversation = currentConversation.copyWith(
          id: response.conversationId,
        );
        // Mettre √† jour aussi la conversation avec le message utilisateur
        final updatedWithBackendId = updatedConversationWithUserMsg.copyWith(
          id: response.conversationId,
        );
        updatedMessages.clear();
        updatedMessages.addAll(updatedWithBackendId.messages);
      } else if (isNewConversation) {
        debugPrint(
          '[AdhaBloc] ‚úÖ Backend a accept√© l\'ID client: $conversationIdForApi',
        );
      }

      final adhaMessage = AdhaMessage(
        id: _uuid.v4(),
        content: response.content,
        timestamp: DateTime.now(),
        sender: AdhaMessageSender.ai,
        type: _detectMessageType(response.content),
      );

      final finalMessages = List<AdhaMessage>.from(updatedMessages)
        ..add(adhaMessage);
      final finalConversation = currentConversation.copyWith(
        messages: finalMessages,
        updatedAt: DateTime.now(),
      );

      await adhaRepository.saveConversation(finalConversation);
      _currentlyActiveConversationId = finalConversation.id; // Set active ID

      emit(
        AdhaConversationActive(
          conversation: finalConversation,
          isProcessing: false,
          isVoiceActive: previousState?.isVoiceActive ?? false,
        ),
      );
    } on AdhaServiceException catch (e) {
      // Gestion sp√©cifique des erreurs du service ADHA
      emit(AdhaError(e.message));
      if (previousState != null) {
        emit(previousState.copyWith(isProcessing: false));
      } else {
        emit(
          AdhaConversationActive(
            conversation: updatedConversationWithUserMsg,
            isProcessing: false,
            isVoiceActive: false,
          ),
        );
      }
    } catch (e) {
      emit(AdhaError("Erreur lors de l'envoi du message: $e"));
      if (previousState != null) {
        emit(previousState.copyWith(isProcessing: false));
      } else {
        // If there was no previous active state, emit a new one based on current conversation
        emit(
          AdhaConversationActive(
            conversation:
                updatedConversationWithUserMsg, // or currentConversation if preferred
            isProcessing: false,
            isVoiceActive: false,
          ),
        );
      }
    }
  }

  Future<void> _onNewConversation(
    NewConversation event,
    Emitter<AdhaState> emit,
  ) async {
    // If the initial message is empty and the source is the new conversation button,
    // or more generally, if we want to reset to the initial suggestion view.
    if (event.initialMessage.isEmpty &&
        event.contextInfo.interactionContext.sourceIdentifier ==
            'new_conversation_button') {
      _currentlyActiveConversationId = null; // Clear active ID
      emit(const AdhaInitial());
      // Optionally, if you want to ensure a default "empty" conversation is ready in the background
      // you could load conversations which might create one if none exist.
      // add(const LoadConversations());
      return;
    }

    emit(const AdhaLoading());
    AdhaConversationActive? previousState =
        state is AdhaConversationActive
            ? (state as AdhaConversationActive)
            : null;
    try {
      final newConversationId = _uuid.v4();
      final userMessage = AdhaMessage(
        id: _uuid.v4(),
        content: event.initialMessage,
        timestamp: DateTime.now(),
        sender: AdhaMessageSender.user,
      );

      final contextInfoForApi = await _buildContextInfo(
        event.contextInfo.interactionContext.interactionType,
        sourceIdentifier: event.contextInfo.interactionContext.sourceIdentifier,
        interactionData: event.contextInfo.interactionContext.interactionData,
      );

      AdhaConversation newConversation = AdhaConversation(
        id: newConversationId,
        title: _generateConversationTitle(event.initialMessage),
        createdAt: DateTime.now(),
        updatedAt: DateTime.now(),
        messages:
            event.initialMessage.isNotEmpty
                ? [userMessage]
                : [], // Ensure messages list is empty if initialMessage is empty
      );

      // If initialMessage is empty, we might not want to immediately process.
      // The AdhaInitial state should be shown.
      // However, the current structure proceeds to send a message.
      // This part might need review if an empty initialMessage is truly intended for _onNewConversation
      // beyond just resetting to AdhaInitial via the button.
      // For now, assuming if initialMessage is not empty, we proceed.

      if (event.initialMessage.isEmpty) {
        // This case should ideally be fully handled by the AdhaInitial emission above
        // if the intent is just to go to suggestions.
        // If a "new blank conversation" is to be created and made active without a message,
        // then _currentlyActiveConversationId should be set.
        // For now, the button press path (empty message) clears the ID and emits AdhaInitial.
        // If this event is called with an empty message NOT from the button,
        // it implies creating a blank, active conversation.
        if (event.contextInfo.interactionContext.sourceIdentifier !=
            'new_conversation_button') {
          await adhaRepository.saveConversation(newConversation);
          _currentlyActiveConversationId = newConversation.id;
          emit(
            AdhaConversationActive(
              conversation: newConversation,
              isProcessing: false,
            ),
          );
        }
        return;
      }

      // Proceed if initialMessage is not empty
      emit(
        AdhaConversationActive(
          conversation: newConversation,
          isProcessing: true,
          isVoiceActive: previousState?.isVoiceActive ?? false,
        ),
      );

      // Pour une nouvelle conversation, ne pas envoyer de conversationId
      final response = await adhaRepository.sendMessage(
        conversationId: null, // Le backend cr√©era la conversation
        message: event.initialMessage,
        contextInfo: contextInfoForApi,
      );

      // Mettre √† jour la conversation avec l'ID du backend
      final conversationWithBackendId = newConversation.copyWith(
        id:
            response.conversationId.isNotEmpty
                ? response.conversationId
                : newConversationId,
      );

      final adhaMessage = AdhaMessage(
        id: _uuid.v4(),
        content: response.content,
        timestamp: DateTime.now(),
        sender: AdhaMessageSender.ai,
        type: _detectMessageType(response.content),
      );

      final updatedConversationWithResponse = conversationWithBackendId
          .copyWith(
            messages: List<AdhaMessage>.from(conversationWithBackendId.messages)
              ..add(adhaMessage),
            updatedAt: DateTime.now(),
          );

      await adhaRepository.saveConversation(updatedConversationWithResponse);
      _currentlyActiveConversationId =
          updatedConversationWithResponse.id; // Set active ID

      emit(
        AdhaConversationActive(
          conversation: updatedConversationWithResponse,
          isProcessing: false,
          isVoiceActive: previousState?.isVoiceActive ?? false,
        ),
      );
    } on AdhaServiceException catch (e) {
      emit(AdhaError(e.message));
    } catch (e) {
      emit(
        AdhaError("Erreur lors de la cr√©ation de la nouvelle conversation: $e"),
      );
    }
  }

  Future<void> _onLoadConversations(
    LoadConversations event,
    Emitter<AdhaState> emit,
  ) async {
    emit(const AdhaLoading());
    try {
      // Case 1: User explicitly wants the initial screen (_currentlyActiveConversationId is null).
      if (_currentlyActiveConversationId == null) {
        emit(const AdhaInitial());
        // Optional: In the background, ensure a default conversation exists if the repository is empty,
        // but don't make it active here as the user wants the initial screen.
        // This part is removed to strictly adhere to showing AdhaInitial if ID is null.
        // If no conversations exist at all, AdhaInitial is fine, user can start one.
        return;
      }

      // Case 2: A specific conversation is supposed to be active. Load it.
      // (_currentlyActiveConversationId is NOT null here)
      final AdhaConversation? conversation = await adhaRepository
          .getConversation(_currentlyActiveConversationId!);
      if (conversation != null) {
        emit(AdhaConversationActive(conversation: conversation));
      } else {
        // The active conversation ID was stored, but the conversation is gone from the repo.
        // This is an inconsistent state. Fallback: clear the active ID and go to AdhaInitial.
        _currentlyActiveConversationId = null; // Clear the bad ID
        emit(const AdhaInitial()); // Go to initial screen as a safe fallback
      }
    } catch (e) {
      _currentlyActiveConversationId =
          null; // Clear on error to prevent broken state
      emit(AdhaError('Erreur lors du chargement des conversations: $e'));
      // Optionally, after error, try to emit AdhaInitial so user is not stuck on error screen.
      // emit(const AdhaInitial());
    }
  }

  Future<void> _onLoadConversation(
    LoadConversation event,
    Emitter<AdhaState> emit,
  ) async {
    emit(const AdhaLoading());
    try {
      final conversation = await adhaRepository.getConversation(
        event.conversationId,
      );
      if (conversation != null) {
        _currentlyActiveConversationId = conversation.id; // Set active ID
        emit(AdhaConversationActive(conversation: conversation));
      } else {
        emit(const AdhaError('Conversation non trouv√©e'));
        add(const LoadConversations());
      }
    } catch (e) {
      emit(AdhaError('Erreur lors du chargement de la conversation: $e'));
    }
  }

  Future<void> _onDeleteConversation(
    DeleteConversation event,
    Emitter<AdhaState> emit,
  ) async {
    try {
      await adhaRepository.deleteConversation(event.conversationId);
      if (_currentlyActiveConversationId == event.conversationId) {
        _currentlyActiveConversationId =
            null; // Clear active ID if it was deleted
      }
      add(
        const LoadConversations(),
      ); // Reload, will go to AdhaInitial if active ID is now null
    } catch (e) {
      emit(AdhaError('Erreur lors de la suppression de la conversation: $e'));
    }
  }

  Future<void> _onStartVoiceRecognition(
    StartVoiceRecognition event,
    Emitter<AdhaState> emit,
  ) async {
    if (state is AdhaConversationActive) {
      final currentState = state as AdhaConversationActive;
      if (!currentState.isProcessing) {
        emit(currentState.copyWith(isVoiceActive: true));
        // _currentlyActiveConversationId remains what it was, voice is just an input method for current/new convo
      }
    } else {
      // This case implies starting voice recognition when not in an active conversation (e.g. from AdhaInitial)
      // A new conversation should be implicitly started or prepared.
      final newConversationId = _uuid.v4();
      final newConversation = AdhaConversation(
        id: newConversationId,
        title: 'Conversation vocale', // Temporary title
        createdAt: DateTime.now(),
        updatedAt: DateTime.now(),
        messages: [],
      );
      // Don't save or set active ID yet, wait for actual speech input.
      // The AdhaConversationActive state here is to enable voice input UI.
      // The actual conversation will be formed by SendMessage after voice input.
      emit(
        AdhaConversationActive(
          conversation: newConversation,
          isVoiceActive: true,
          isProcessing: false,
        ),
      );
      // _currentlyActiveConversationId should ideally be set when the first message from voice is processed.
      // For now, if voice is started from AdhaInitial, _currentlyActiveConversationId is still null.
      // SendMessage will handle creating/activating the conversation.
    }
  }

  Future<void> _onStopVoiceRecognition(
    StopVoiceRecognition event,
    Emitter<AdhaState> emit,
  ) async {
    if (state is AdhaConversationActive) {
      final currentState = state as AdhaConversationActive;
      emit(currentState.copyWith(isVoiceActive: false));
    }
  }

  String _generateConversationTitle(String firstMessage) {
    String title = firstMessage.replaceAll('\n', ' ');
    if (title.length > 30) {
      title = '${title.substring(0, 27)}...';
    }
    return title.isEmpty ? "Nouvelle Conversation" : title;
  }

  AdhaMessageType _detectMessageType(String content) {
    if (content.contains('```')) {
      return AdhaMessageType.code;
    } else if (content.contains(r'\begin{equation}') ||
        content.contains(r'$$')) {
      return AdhaMessageType.latex;
    } else if (content.contains('<graph>') || content.contains('plt.show()')) {
      return AdhaMessageType.graph;
    }
    return AdhaMessageType.text;
  }

  // G√®re la modification d\'un message par l\'utilisateur
  Future<void> _onEditMessage(
    EditMessage event,
    Emitter<AdhaState> emit,
  ) async {
    if (state is! AdhaConversationActive) {
      emit(
        const AdhaError(
          "Impossible de modifier un message : aucune conversation active.",
        ),
      );
      return;
    }

    final currentState = state as AdhaConversationActive;
    AdhaConversation currentConversation = currentState.conversation;

    int messageIndex = currentConversation.messages.indexWhere(
      (msg) => msg.id == event.messageId,
    );

    if (messageIndex == -1) {
      emit(
        AdhaError(
          "Impossible de modifier le message : ID non trouv√© (${event.messageId}).",
        ),
      );
      return;
    }

    // Create the updated user message
    final editedUserMessage = currentConversation.messages[messageIndex]
        .copyWith(
          content: event.newContent,
          timestamp: DateTime.now(), // Update timestamp to reflect edit time
        );

    // Create a new list of messages, truncated up to the edited message
    final List<AdhaMessage> messagesUpToEdited = List.from(
      currentConversation.messages.take(messageIndex),
    );
    messagesUpToEdited.add(editedUserMessage); // Add the edited message

    final updatedConversationWithUserMsg = currentConversation.copyWith(
      messages: messagesUpToEdited,
      updatedAt: DateTime.now(),
      // Optionally, update the conversation title if the first message was edited
      title:
          messageIndex == 0
              ? _generateConversationTitle(event.newContent)
              : currentConversation.title,
    );

    emit(
      AdhaConversationActive(
        conversation: updatedConversationWithUserMsg,
        isProcessing: true, // Indicate processing as we will send to API
        isVoiceActive: currentState.isVoiceActive,
      ),
    );

    try {
      // Use the contextInfo from the event.
      // The EditMessage event requires contextInfo, so it won't be null.
      final AdhaContextInfo contextInfoForApi = event.contextInfo;

      final response = await adhaRepository.sendMessage(
        conversationId: currentConversation.id, // Use existing conversation ID
        message: event.newContent, // Send the new content
        contextInfo: contextInfoForApi,
        // Consider adding a parameter to sendMessage like `isEdit: true`
        // if the backend needs to specifically know this is a regeneration.
      );

      final adhaResponseMessage = AdhaMessage(
        id: _uuid.v4(),
        content: response.content,
        timestamp: DateTime.now(),
        sender: AdhaMessageSender.ai,
        type: _detectMessageType(response.content),
      );

      final finalMessages = List<AdhaMessage>.from(messagesUpToEdited)
        ..add(adhaResponseMessage);
      final finalConversation = updatedConversationWithUserMsg.copyWith(
        messages: finalMessages,
        updatedAt: DateTime.now(),
      );

      await adhaRepository.saveConversation(finalConversation);
      _currentlyActiveConversationId = finalConversation.id;

      emit(
        AdhaConversationActive(
          conversation: finalConversation,
          isProcessing: false,
          isVoiceActive: currentState.isVoiceActive,
        ),
      );
    } on AdhaServiceException catch (e) {
      emit(AdhaError(e.message));
      // Revert to the state before attempting to send the edited message
      emit(
        currentState.copyWith(
          isProcessing: false,
          conversation: updatedConversationWithUserMsg,
        ),
      );
    } catch (e) {
      emit(AdhaError("Erreur lors de la modification du message: $e"));
      // Revert to the state before attempting to send the edited message,
      // but keep user's edit locally in the conversation object for the UI.
      emit(
        currentState.copyWith(
          isProcessing: false,
          conversation: updatedConversationWithUserMsg,
        ),
      );
    }
  }

  /// Initialise les listeners pour le service audio
  void _initAudioListeners() {
    // √âcouter les changements de connexion
    _audioConnectionSubscription = _audioStreamingService.connectionState
        .listen((connectionState) {
          add(
            AudioStateUpdate(
              connectionState: _mapServiceToStateConnectionState(
                connectionState,
              ),
              isRecording: false,
              isPlaying: false,
              audioLevel: 0.0,
            ),
          );
        });

    // √âcouter les changements d'enregistrement
    _isRecordingSubscription = _audioStreamingService.isRecording.listen((
      isRecording,
    ) {
      // Utiliser add() au lieu d'emit() dans les listeners
      add(
        AudioStateUpdate(
          connectionState:
              state is AdhaConversationActive
                  ? (state as AdhaConversationActive).audioConnectionState
                  : AudioConnectionState.disconnected,
          isRecording: isRecording,
          isPlaying:
              state is AdhaConversationActive
                  ? (state as AdhaConversationActive).isAdhaPlaying
                  : false,
          audioLevel:
              state is AdhaConversationActive
                  ? (state as AdhaConversationActive).audioLevel
                  : 0.0,
        ),
      );
    });

    // √âcouter les changements de lecture
    _isPlayingSubscription = _audioStreamingService.isPlaying.listen((
      isPlaying,
    ) {
      add(
        AudioStateUpdate(
          connectionState:
              state is AdhaConversationActive
                  ? (state as AdhaConversationActive).audioConnectionState
                  : AudioConnectionState.disconnected,
          isRecording:
              state is AdhaConversationActive
                  ? (state as AdhaConversationActive).isRecording
                  : false,
          isPlaying: isPlaying,
          audioLevel:
              state is AdhaConversationActive
                  ? (state as AdhaConversationActive).audioLevel
                  : 0.0,
        ),
      );
    });

    // √âcouter les changements de niveau audio
    _audioLevelSubscription = _audioStreamingService.audioLevel.listen((
      audioLevel,
    ) {
      add(
        AudioStateUpdate(
          connectionState:
              state is AdhaConversationActive
                  ? (state as AdhaConversationActive).audioConnectionState
                  : AudioConnectionState.disconnected,
          isRecording:
              state is AdhaConversationActive
                  ? (state as AdhaConversationActive).isRecording
                  : false,
          isPlaying:
              state is AdhaConversationActive
                  ? (state as AdhaConversationActive).isAdhaPlaying
                  : false,
          audioLevel: audioLevel,
        ),
      );
    });
  }

  /// D√©marre une session audio
  Future<void> _onStartAudioSession(
    StartAudioSession event,
    Emitter<AdhaState> emit,
  ) async {
    if (state is! AdhaConversationActive) {
      emit(
        const AdhaError(
          "Impossible de d√©marrer une session audio sans conversation active",
        ),
      );
      return;
    }

    final currentState = state as AdhaConversationActive;

    try {
      // Configuration du service audio
      _audioStreamingService.configure(
        wsUrl: 'wss://api.wanzo.com/ws', // URL √† configurer
        headers: {'Authorization': 'Bearer ${await _getAuthToken()}'},
      );

      // Construire le contexte
      final contextInfo =
          event.contextInfo ??
          await _buildContextInfo(
            AdhaInteractionType.genericCardAnalysis,
            sourceIdentifier: 'audio_session_start',
            conversationId: currentState.conversation.id,
          );

      // D√©marrer la session
      await _audioStreamingService.startAudioSession(
        conversationId: currentState.conversation.id,
        contextInfo: contextInfo.toJson(),
      );

      emit(
        currentState.copyWith(
          isAudioStreamingActive: true,
          audioConnectionState: AudioConnectionState.connecting,
        ),
      );
    } catch (e) {
      emit(AdhaError("Erreur de d√©marrage de la session audio: $e"));
    }
  }

  /// Termine une session audio
  Future<void> _onEndAudioSession(
    EndAudioSession event,
    Emitter<AdhaState> emit,
  ) async {
    if (state is! AdhaConversationActive) return;

    final currentState = state as AdhaConversationActive;

    try {
      await _audioStreamingService.endSession();

      emit(
        currentState.copyWith(
          isAudioStreamingActive: false,
          audioConnectionState: AudioConnectionState.disconnected,
          isRecording: false,
          isAdhaPlaying: false,
          audioLevel: 0.0,
        ),
      );
    } catch (e) {
      emit(AdhaError("Erreur de fermeture de la session audio: $e"));
    }
  }

  /// G√®re l'activation/d√©sactivation de l'enregistrement
  Future<void> _onToggleRecording(
    ToggleRecording event,
    Emitter<AdhaState> emit,
  ) async {
    if (state is! AdhaConversationActive) return;

    final currentState = state as AdhaConversationActive;

    if (!currentState.isAudioStreamingActive) {
      emit(const AdhaError("Session audio non active"));
      return;
    }

    try {
      await _audioStreamingService.togglePushToTalk(event.enabled);

      // L'√©tat sera mis √† jour via les listeners
    } catch (e) {
      emit(AdhaError("Erreur de contr√¥le de l'enregistrement: $e"));
    }
  }

  /// Interrompt Adha pendant qu'il parle
  Future<void> _onInterruptAdha(
    InterruptAdha event,
    Emitter<AdhaState> emit,
  ) async {
    if (state is! AdhaConversationActive) return;

    final currentState = state as AdhaConversationActive;

    if (!currentState.isAudioStreamingActive) return;

    try {
      await _audioStreamingService.interrupt();

      // L'√©tat sera mis √† jour via les listeners
    } catch (e) {
      emit(AdhaError("Erreur d'interruption: $e"));
    }
  }

  /// Ajuste le volume audio
  Future<void> _onSetAudioVolume(
    SetAudioVolume event,
    Emitter<AdhaState> emit,
  ) async {
    try {
      await _audioStreamingService.setVolume(event.volume);
    } catch (e) {
      emit(AdhaError("Erreur de r√©glage du volume: $e"));
    }
  }

  /// G√®re les mises √† jour d'√©tat audio
  Future<void> _onAudioStateUpdate(
    AudioStateUpdate event,
    Emitter<AdhaState> emit,
  ) async {
    if (state is! AdhaConversationActive) return;

    final currentState = state as AdhaConversationActive;

    emit(
      currentState.copyWith(
        audioConnectionState: event.connectionState,
        isRecording: event.isRecording,
        isAdhaPlaying: event.isPlaying,
        audioLevel: event.audioLevel,
      ),
    );
  }

  /// R√©cup√®re le token d'authentification
  Future<String> _getAuthToken() async {
    // Impl√©mentation √† adapter selon votre syst√®me d'auth
    final user = await authRepository.getCurrentUser();
    // Utilisation d'un field qui existe dans le mod√®le User
    return user?.id ?? ''; // ou user?.email ?? '' selon votre impl√©mentation
  }

  // ============================================================================
  // M√âTHODES DE STREAMING (Janvier 2026)
  // ============================================================================

  /// Initialise les listeners pour le service de streaming
  void _initStreamListeners() {
    // √âcouter les chunks de streaming
    _streamChunkSubscription = _streamService.chunkStream.listen(
      _handleStreamChunk,
      onError: (error) {
        add(
          StreamError(
            conversationId: _currentlyActiveConversationId ?? '',
            errorMessage: error.toString(),
            requestMessageId: _currentStreamingRequestId,
          ),
        );
      },
    );

    // √âcouter les changements de connexion
    _streamConnectionSubscription = _streamService.connectionState.listen((
      connectionState,
    ) {
      // Mapper l'√©tat de connexion du service vers l'√©tat du bloc
      // Note: Les changements d'√©tat de connexion sont g√©r√©s via les √©v√©nements
      // ConnectToStreamService et DisconnectFromStreamService
      // Ce listener est utilis√© pour le logging/debugging
      debugPrint('[AdhaBloc] Stream connection state: ${connectionState.name}');
    });
  }

  /// G√®re les chunks de streaming re√ßus
  void _handleStreamChunk(AdhaStreamChunkEvent chunk) {
    switch (chunk.type) {
      case AdhaStreamType.chunk:
        // Fragment de texte normal
        // L'accumulation est faite dans _onStreamChunkReceived
        add(
          StreamChunkReceived(
            conversationId: chunk.conversationId,
            content: chunk.content,
            chunkId: chunk.chunkId,
            requestMessageId: chunk.requestMessageId,
          ),
        );
        break;

      case AdhaStreamType.end:
        // Fin du streaming - utiliser le contenu accumul√©
        // IMPORTANT: Attendre un court instant pour que les chunks en queue soient trait√©s
        // avant de finaliser le streaming. Les √©v√©nements arrivent de mani√®re asynchrone
        // et le 'end' peut arriver avant que tous les 'chunk' events ne soient trait√©s.
        Future.delayed(const Duration(milliseconds: 100), () {
          final accumulatedContent = _accumulatedStreamContent.toString();
          debugPrint(
            '[AdhaBloc] üìù StreamEnd trait√© - contenu accumul√©: ${accumulatedContent.length} caract√®res',
          );
          add(
            StreamCompleted(
              conversationId: chunk.conversationId,
              fullContent:
                  accumulatedContent.isNotEmpty
                      ? accumulatedContent
                      : chunk.content,
              requestMessageId: chunk.requestMessageId,
              totalChunks: chunk.totalChunks ?? chunk.chunkId,
              processingDetails: chunk.processingDetails,
            ),
          );
        });
        break;

      case AdhaStreamType.error:
        // Erreur pendant le streaming
        add(
          StreamError(
            conversationId: chunk.conversationId,
            errorMessage: chunk.content,
            requestMessageId: chunk.requestMessageId,
          ),
        );
        break;

      case AdhaStreamType.toolCall:
      case AdhaStreamType.toolResult:
        // Appels de fonctions IA - optionnel: afficher un indicateur
        // Pour l'instant, on les ignore silencieusement
        break;

      case AdhaStreamType.cancelled:
        // Stream annul√© par l'utilisateur ou le serveur (v2.4.0)
        add(CancelStreaming(conversationId: chunk.conversationId));
        break;

      case AdhaStreamType.heartbeat:
        // Heartbeat - signal de connexion active (v2.4.0)
        // Ne n√©cessite aucune action, juste pour maintenir la connexion
        debugPrint('[AdhaBloc] üíì Heartbeat re√ßu');
        break;
    }
  }

  /// Connecte au service de streaming
  ///
  /// Selon la documentation ADHA (Janvier 2026):
  /// - Connexion via Socket.IO √† l'API Gateway (/commerce/chat)
  /// - Authentification via token JWT dans l'objet auth
  Future<void> _onConnectToStreamService(
    ConnectToStreamService event,
    Emitter<AdhaState> emit,
  ) async {
    try {
      final businessContextService = BusinessContextService();

      if (!businessContextService.isInitialized ||
          businessContextService.companyId == null) {
        await authRepository.getUser(forceRemote: true);
      }

      if (!businessContextService.isInitialized ||
          businessContextService.companyId == null) {
        emit(
          const AdhaStreamConnected(
            connectionState: StreamConnectionState.error,
            errorMessage:
                'Contexte business indisponible. Veuillez r√©essayer apr√®s la r√©cup√©ration du profil (/users/me).',
          ),
        );
        return;
      }

      // R√©cup√©rer le token d'authentification
      final authToken = event.authToken ?? await _getAuthToken();

      if (authToken.isEmpty) {
        emit(
          const AdhaStreamConnected(
            connectionState: StreamConnectionState.error,
            errorMessage: 'Token d\'authentification manquant',
          ),
        );
        return;
      }

      // Connecter au service de streaming avec le token JWT
      await _streamService.connect(authToken);

      emit(
        const AdhaStreamConnected(
          connectionState: StreamConnectionState.connected,
        ),
      );
    } catch (e) {
      emit(
        AdhaStreamConnected(
          connectionState: StreamConnectionState.error,
          errorMessage: e.toString(),
        ),
      );
    }
  }

  /// D√©connecte du service de streaming
  Future<void> _onDisconnectFromStreamService(
    DisconnectFromStreamService event,
    Emitter<AdhaState> emit,
  ) async {
    await _streamService.disconnect();

    emit(
      const AdhaStreamConnected(
        connectionState: StreamConnectionState.disconnected,
      ),
    );
  }

  /// Envoie un message avec streaming
  Future<void> _onSendStreamingMessage(
    SendStreamingMessage event,
    Emitter<AdhaState> emit,
  ) async {
    AdhaConversation currentConversation;
    AdhaContextInfo contextInfoForApi;
    bool isNewConversation = false;
    String? conversationIdForApi;

    // R√©initialiser le buffer de streaming
    _accumulatedStreamContent.clear();

    // R√©cup√©rer companyId et userId pour les envoyer au backend ADHA
    // Le companyId n'est PAS dans le JWT, donc on doit l'envoyer explicitement
    // Le userId doit √™tre l'UUID de la base de donn√©es, pas l'Auth0 ID
    final businessContextService = BusinessContextService();
    final companyId = businessContextService.companyId;
    final userId = businessContextService.userId; // UUID de la DB, pas Auth0 ID

    debugPrint(
      '[AdhaBloc] companyId: $companyId, userId: $userId pour requ√™te ADHA',
    );

    // D√©terminer ou cr√©er la conversation
    // NOUVEAU (Janvier 2026): Le frontend g√©n√®re toujours le conversationId
    // pour permettre la souscription WebSocket AVANT l'envoi du message.
    // Le backend DOIT accepter ce conversationId fourni par le client.
    if (state is AdhaConversationActive) {
      final currentState = state as AdhaConversationActive;
      currentConversation = currentState.conversation;
      conversationIdForApi = currentConversation.id; // Conversation existante
      contextInfoForApi = await _buildContextInfo(
        event.contextInfo?.interactionContext.interactionType ??
            AdhaInteractionType.followUp,
        sourceIdentifier:
            event.contextInfo?.interactionContext.sourceIdentifier,
        interactionData: event.contextInfo?.interactionContext.interactionData,
        conversationId: currentConversation.id,
      );
    } else if (state is AdhaStreaming) {
      // D√©j√† en streaming, ignorer
      return;
    } else {
      if (event.contextInfo == null) {
        emit(
          const AdhaError(
            "ContextInfo est requis pour d√©marrer une nouvelle conversation.",
          ),
        );
        return;
      }
      isNewConversation = true;
      // NOUVEAU: Le frontend g√©n√®re le conversationId (UUID)
      // et l'envoie au backend pour permettre le streaming d√®s le premier message
      final clientGeneratedConversationId = _uuid.v4();
      conversationIdForApi = clientGeneratedConversationId; // Envoy√© au backend
      debugPrint(
        '[AdhaBloc] üÜï Nouvelle conversation - ID g√©n√©r√© c√¥t√© client: $clientGeneratedConversationId',
      );
      currentConversation = AdhaConversation(
        id: clientGeneratedConversationId, // ID g√©n√©r√© c√¥t√© client
        title: _generateConversationTitle(event.message),
        createdAt: DateTime.now(),
        updatedAt: DateTime.now(),
        messages: [],
      );
      contextInfoForApi = await _buildContextInfo(
        event.contextInfo!.interactionContext.interactionType,
        sourceIdentifier:
            event.contextInfo!.interactionContext.sourceIdentifier,
        interactionData: event.contextInfo!.interactionContext.interactionData,
        conversationId:
            clientGeneratedConversationId, // Inclure l'ID dans le contexte
      );
    }

    // Cr√©er le message utilisateur
    final requestMessageId = _uuid.v4();
    _currentStreamingRequestId = requestMessageId;

    final userMessage = AdhaMessage(
      id: requestMessageId,
      content: event.message,
      timestamp: DateTime.now(),
      sender: AdhaMessageSender.user,
    );

    final updatedMessages = List<AdhaMessage>.from(currentConversation.messages)
      ..add(userMessage);
    final updatedConversation = currentConversation.copyWith(
      messages: updatedMessages,
      updatedAt: DateTime.now(),
    );

    // √âmettre l'√©tat de streaming
    // NOUVEAU (Janvier 2026): L'ID est g√©n√©r√© c√¥t√© client, donc isPendingConversationId=false
    // car on a d√©j√† l'ID final (pas besoin d'attendre le backend)
    emit(
      AdhaStreaming(
        conversation: updatedConversation,
        partialContent: '',
        currentChunkId: 0,
        requestMessageId: requestMessageId,
        conversationId: currentConversation.id,
        isStreaming: true,
        isPendingConversationId: false, // ID g√©n√©r√© c√¥t√© client, pas en attente
      ),
    );

    // S'assurer que la connexion WebSocket est active avant d'envoyer
    // Si la connexion a √©t√© perdue (timeout, app en arri√®re-plan, etc.), reconnecter
    final isWebSocketConnected = await _streamService.ensureConnected();

    // V√©rifier la connexion au service de streaming
    if (!isWebSocketConnected) {
      debugPrint(
        '[AdhaBloc] WebSocket non connect√© - utilisation du mode synchrone',
      );
      // Fallback vers l'envoi classique si non connect√©
      try {
        final response = await adhaRepository.sendMessage(
          conversationId:
              conversationIdForApi, // null pour nouvelle conversation
          message: event.message,
          contextInfo: contextInfoForApi,
          companyId: companyId,
          userId: userId,
        );

        // Si c'√©tait une nouvelle conversation, mettre √† jour l'ID avec celui du backend
        String finalConversationId = currentConversation.id;
        if (isNewConversation && response.conversationId.isNotEmpty) {
          finalConversationId = response.conversationId;
          currentConversation = currentConversation.copyWith(
            id: response.conversationId,
          );
          // Mettre √† jour la conversation dans l'√©tat avec l'ID confirm√© du backend
          final updatedWithBackendId = updatedConversation.copyWith(
            id: response.conversationId,
          );
          emit(
            AdhaStreaming(
              conversation: updatedWithBackendId,
              partialContent: '',
              currentChunkId: 0,
              requestMessageId: requestMessageId,
              conversationId: response.conversationId,
              isStreaming: true,
              isPendingConversationId: false, // ID confirm√© par le backend
            ),
          );
        }

        // Simuler la fin du streaming
        add(
          StreamCompleted(
            conversationId: finalConversationId,
            fullContent: response.content,
            requestMessageId: requestMessageId,
            totalChunks: 1,
          ),
        );
      } on AdhaServiceException catch (e) {
        add(
          StreamError(
            conversationId: currentConversation.id,
            errorMessage: e.message,
            requestMessageId: requestMessageId,
          ),
        );
      } catch (e) {
        add(
          StreamError(
            conversationId: currentConversation.id,
            errorMessage: e.toString(),
            requestMessageId: requestMessageId,
          ),
        );
      }
      return;
    }

    // NOUVEAU (Janvier 2026): Le frontend g√©n√®re le conversationId
    // On peut maintenant s'abonner √† la room WebSocket AVANT d'envoyer le message
    // pour TOUTES les conversations (nouvelles ou existantes).
    // Cela permet le vrai streaming temps r√©el d√®s le premier message.

    // S'abonner AVANT d'envoyer le message (nouvelle ou existante)
    debugPrint(
      '[AdhaBloc] üìù Souscription WebSocket √† ${currentConversation.id} AVANT envoi du message',
    );
    _streamService.subscribeToConversation(currentConversation.id);

    // Petit d√©lai pour s'assurer que la souscription est bien enregistr√©e c√¥t√© serveur
    await Future.delayed(const Duration(milliseconds: 100));

    try {
      // NOUVEAU (Janvier 2026): Streaming activ√© pour TOUTES les conversations
      // Le frontend envoie le conversationId g√©n√©r√© c√¥t√© client
      // Le backend utilise cet ID au lieu d'en g√©n√©rer un nouveau

      if (isNewConversation && event.streaming && _streamService.isConnected) {
        // Nouvelle conversation avec streaming: envoyer via /stream avec l'ID g√©n√©r√©
        debugPrint(
          '[AdhaBloc] üöÄ Nouvelle conversation - STREAMING avec ID client: ${currentConversation.id}',
        );

        final streamResponse = await adhaRepository.sendStreamingMessage(
          conversationId: conversationIdForApi, // ID g√©n√©r√© c√¥t√© client!
          message: event.message,
          contextInfo: contextInfoForApi,
          attachments: event.attachments,
          companyId: companyId,
          userId: userId,
        );

        // Les chunks arriveront via Socket.IO (client d√©j√† abonn√©)
        debugPrint(
          '[AdhaBloc] ‚úÖ Streaming initi√© pour nouvelle conv - requestMessageId: ${streamResponse.requestMessageId}',
        );
        // Ne pas faire de add() ici, les chunks arrivent via WebSocket
        return;
      } else if (isNewConversation) {
        // Fallback: nouvelle conversation SANS streaming (WebSocket non connect√©)
        debugPrint(
          '[AdhaBloc] ‚ö†Ô∏è Nouvelle conversation - WebSocket non disponible, fallback synchrone',
        );

        // Mode synchrone pour nouvelle conversation (fallback)
        final response = await adhaRepository.sendMessage(
          conversationId: conversationIdForApi, // ID g√©n√©r√© c√¥t√© client!
          message: event.message,
          contextInfo: contextInfoForApi,
          companyId: companyId,
          userId: userId,
        );

        // L'ID de conversation reste celui g√©n√©r√© par le client
        // Le backend DOIT utiliser cet ID, mais on v√©rifie quand m√™me la r√©ponse
        final responseConversationId = response.conversationId;

        // Si le backend retourne un ID diff√©rent (ancien comportement), logger un warning
        if (responseConversationId.isNotEmpty &&
            responseConversationId != conversationIdForApi) {
          debugPrint(
            '[AdhaBloc] ‚ö†Ô∏è Backend a retourn√© un ID diff√©rent: $responseConversationId vs $conversationIdForApi',
          );
          debugPrint(
            '[AdhaBloc] ‚ö†Ô∏è Le backend doit √™tre mis √† jour pour accepter l\'ID du client',
          );
          // Utiliser l'ID du backend si diff√©rent (compatibilit√© ancienne version)
          currentConversation = currentConversation.copyWith(
            id: responseConversationId,
          );
          final updatedWithBackendId = updatedConversation.copyWith(
            id: responseConversationId,
          );
          // S'abonner avec le nouvel ID si diff√©rent
          _streamService.subscribeToConversation(responseConversationId);

          // CORRECTION: Le backend peut avoir stream√© la r√©ponse via Kafka/WebSocket
          // et sauvegard√© en DB AVANT que la r√©ponse HTTP n'arrive.
          // Si response.content est vide ou contient un message d'erreur timeout,
          // r√©cup√©rer l'historique de la conversation depuis la DB.
          String aiResponseContent = response.content;

          debugPrint(
            '[AdhaBloc] R√©ponse HTTP re√ßue: "${aiResponseContent.substring(0, aiResponseContent.length > 100 ? 100 : aiResponseContent.length)}..."',
          );

          // D√©tecter si c'est un message de timeout
          final isTimeout =
              aiResponseContent.isEmpty ||
              aiResponseContent.contains('d√©lai raisonnable') ||
              aiResponseContent.contains('delai raisonnable') || // Sans accent
              aiResponseContent.contains('timeout') ||
              aiResponseContent.contains('r√©essayer plus tard') ||
              aiResponseContent.contains(
                'reessayer plus tard',
              ) || // Sans accent
              aiResponseContent.contains('pas pu traiter votre demande');

          debugPrint('[AdhaBloc] isTimeout=$isTimeout');

          if (isTimeout) {
            debugPrint(
              '[AdhaBloc] R√©ponse HTTP vide/timeout - r√©cup√©ration depuis l\'historique DB',
            );

            // Attendre un court instant pour que la DB soit √† jour
            await Future.delayed(const Duration(milliseconds: 500));

            // R√©cup√©rer l'historique de la conversation
            try {
              debugPrint(
                '[AdhaBloc] R√©cup√©ration historique pour $responseConversationId...',
              );
              final history = await adhaRepository
                  .fetchConversationHistoryFromServer(responseConversationId);

              debugPrint(
                '[AdhaBloc] Historique r√©cup√©r√©: ${history.length} messages',
              );

              // Log tous les messages pour debug
              for (int i = 0; i < history.length; i++) {
                final m = history[i];
                debugPrint(
                  '[AdhaBloc] Message[$i]: sender=${m.sender}, content="${m.content.substring(0, m.content.length > 50 ? 50 : m.content.length)}..."',
                );
              }

              // Trouver les messages AI qui ne sont PAS des messages de timeout
              // Le backend peut avoir ins√©r√© un message timeout APR√àS le vrai message AI
              final validAiMessages =
                  history
                      .where(
                        (m) =>
                            m.sender == AdhaMessageSender.ai &&
                            !m.content.contains('d√©lai raisonnable') &&
                            !m.content.contains('delai raisonnable') &&
                            !m.content.contains('r√©essayer plus tard') &&
                            !m.content.contains('reessayer plus tard') &&
                            !m.content.contains('pas pu traiter votre demande'),
                      )
                      .toList();

              debugPrint(
                '[AdhaBloc] Messages AI valides trouv√©s: ${validAiMessages.length}',
              );

              if (validAiMessages.isNotEmpty) {
                // Prendre le dernier message AI valide (le plus r√©cent qui n'est pas un timeout)
                final validAiMessage = validAiMessages.last;
                aiResponseContent = validAiMessage.content;
                debugPrint(
                  '[AdhaBloc] ‚úÖ R√©ponse AI r√©cup√©r√©e depuis DB: ${aiResponseContent.length} caract√®res',
                );
              } else {
                debugPrint(
                  '[AdhaBloc] ‚ö†Ô∏è Aucun message AI valide trouv√© dans l\'historique',
                );
              }
            } catch (e) {
              debugPrint('[AdhaBloc] Erreur r√©cup√©ration historique: $e');
            }
          }

          emit(
            AdhaStreaming(
              conversation: updatedWithBackendId,
              partialContent: aiResponseContent,
              currentChunkId: 1,
              requestMessageId: requestMessageId,
              conversationId: responseConversationId,
              isStreaming: true,
              isPendingConversationId: false,
            ),
          );

          // Compl√©ter le streaming avec le contenu r√©cup√©r√©
          add(
            StreamCompleted(
              conversationId: responseConversationId,
              fullContent: aiResponseContent,
              requestMessageId: requestMessageId,
              totalChunks: 1,
            ),
          );
        } else {
          // Backend a utilis√© l'ID fourni par le client - comportement attendu
          debugPrint(
            '[AdhaBloc] ‚úÖ Backend a utilis√© l\'ID client: $conversationIdForApi',
          );

          // Compl√©ter le streaming avec la r√©ponse directe
          add(
            StreamCompleted(
              conversationId: currentConversation.id,
              fullContent: response.content,
              requestMessageId: requestMessageId,
              totalChunks: 1,
            ),
          );
        }
      } else if (event.streaming && _streamService.isConnected) {
        // Conversation existante + streaming activ√© + connect√©: utiliser le streaming
        debugPrint(
          '[AdhaBloc] Conversation existante - utilisation du mode streaming',
        );

        final streamResponse = await adhaRepository.sendStreamingMessage(
          conversationId: conversationIdForApi,
          message: event.message,
          contextInfo: contextInfoForApi,
          attachments: event.attachments,
          companyId: companyId,
          userId: userId,
        );

        // Les chunks arriveront via Socket.IO (client d√©j√† abonn√©)
        debugPrint(
          '[AdhaBloc] Streaming initi√© - requestMessageId: ${streamResponse.requestMessageId}',
        );
      } else {
        // Fallback: mode synchrone
        debugPrint('[AdhaBloc] Fallback vers mode synchrone');

        final response = await adhaRepository.sendMessage(
          conversationId: conversationIdForApi,
          message: event.message,
          contextInfo: contextInfoForApi,
          companyId: companyId,
          userId: userId,
        );

        add(
          StreamCompleted(
            conversationId: currentConversation.id,
            fullContent: response.content,
            requestMessageId: requestMessageId,
            totalChunks: 1,
          ),
        );
      }
    } on AdhaServiceException catch (e) {
      add(
        StreamError(
          conversationId: currentConversation.id,
          errorMessage: e.message,
          requestMessageId: requestMessageId,
        ),
      );
    } catch (e) {
      add(
        StreamError(
          conversationId: currentConversation.id,
          errorMessage: e.toString(),
          requestMessageId: requestMessageId,
        ),
      );
    }
  }

  /// G√®re la r√©ception d'un chunk de streaming
  Future<void> _onStreamChunkReceived(
    StreamChunkReceived event,
    Emitter<AdhaState> emit,
  ) async {
    if (state is! AdhaStreaming) {
      debugPrint(
        '[AdhaBloc] ‚ö†Ô∏è Chunk re√ßu mais √©tat n\'est pas AdhaStreaming: ${state.runtimeType}',
      );
      return;
    }

    final currentState = state as AdhaStreaming;

    // CORRECTION (Janvier 2026): Utiliser le conversationId pour filtrer les chunks
    // au lieu du requestMessageId qui n'est pas coh√©rent entre client et backend.
    // Le conversationId est maintenant g√©n√©r√© c√¥t√© client et utilis√© des deux c√¥t√©s.
    if (currentState.conversationId != event.conversationId) {
      debugPrint(
        '[AdhaBloc] ‚ö†Ô∏è Chunk ignor√©: conversationId mismatch (state: ${currentState.conversationId}, event: ${event.conversationId})',
      );
      return;
    }

    debugPrint(
      '[AdhaBloc] ‚úÖ Chunk #${event.chunkId} accept√© pour ${event.conversationId}: "${event.content}"',
    );

    // Accumuler le contenu
    _accumulatedStreamContent.write(event.content);

    // √âmettre le nouvel √©tat avec le contenu accumul√©
    emit(currentState.appendContent(event.content, event.chunkId));
  }

  /// G√®re la fin du streaming
  Future<void> _onStreamCompleted(
    StreamCompleted event,
    Emitter<AdhaState> emit,
  ) async {
    AdhaConversation conversation;

    if (state is AdhaStreaming) {
      final streamingState = state as AdhaStreaming;
      conversation = streamingState.conversation;
    } else if (state is AdhaConversationActive) {
      conversation = (state as AdhaConversationActive).conversation;
    } else {
      // √âtat inattendu, r√©cup√©rer la conversation depuis le repository
      final conv = await adhaRepository.getConversation(event.conversationId);
      if (conv == null) {
        emit(AdhaError("Conversation non trouv√©e: ${event.conversationId}"));
        return;
      }
      conversation = conv;
    }

    // Cr√©er le message de r√©ponse d'ADHA
    final adhaMessage = AdhaMessage(
      id: _uuid.v4(),
      content: event.fullContent,
      timestamp: DateTime.now(),
      sender: AdhaMessageSender.ai,
      type: _detectMessageType(event.fullContent),
    );

    final finalMessages = List<AdhaMessage>.from(conversation.messages)
      ..add(adhaMessage);
    final finalConversation = conversation.copyWith(
      messages: finalMessages,
      updatedAt: DateTime.now(),
    );

    // Sauvegarder la conversation
    await adhaRepository.saveConversation(finalConversation);
    _currentlyActiveConversationId = finalConversation.id;

    // R√©initialiser le buffer et l'ID de streaming
    _accumulatedStreamContent.clear();
    _currentStreamingRequestId = null;

    emit(
      AdhaConversationActive(
        conversation: finalConversation,
        isProcessing: false,
      ),
    );
  }

  /// G√®re les erreurs de streaming
  Future<void> _onStreamError(
    StreamError event,
    Emitter<AdhaState> emit,
  ) async {
    _accumulatedStreamContent.clear();
    _currentStreamingRequestId = null;

    emit(AdhaError("Erreur de streaming: ${event.errorMessage}"));

    // Restaurer l'√©tat de conversation si disponible
    if (event.conversationId.isNotEmpty) {
      final conversation = await adhaRepository.getConversation(
        event.conversationId,
      );
      if (conversation != null) {
        emit(
          AdhaConversationActive(
            conversation: conversation,
            isProcessing: false,
          ),
        );
      }
    }
  }

  /// Annule le streaming en cours
  Future<void> _onCancelStreaming(
    CancelStreaming event,
    Emitter<AdhaState> emit,
  ) async {
    _accumulatedStreamContent.clear();
    _currentStreamingRequestId = null;

    if (state is AdhaStreaming) {
      final streamingState = state as AdhaStreaming;
      emit(
        AdhaConversationActive(
          conversation: streamingState.conversation,
          isProcessing: false,
        ),
      );
    }
  }

  /// R√©initialise l'√©tat pour d√©marrer une nouvelle conversation
  Future<void> _onClearCurrentConversation(
    ClearCurrentConversation event,
    Emitter<AdhaState> emit,
  ) async {
    _currentlyActiveConversationId = null;
    _accumulatedStreamContent.clear();
    _currentStreamingRequestId = null;
    emit(const AdhaInitial());
  }

  /// Initialise le repository pour un utilisateur sp√©cifique
  /// Appel√© apr√®s la connexion pour isoler les conversations par utilisateur
  Future<void> _onInitializeForUser(
    InitializeForUser event,
    Emitter<AdhaState> emit,
  ) async {
    try {
      debugPrint('[AdhaBloc] Initialisation pour utilisateur: ${event.userId}');

      // R√©initialiser l'√©tat
      _currentlyActiveConversationId = null;
      _accumulatedStreamContent.clear();
      _currentStreamingRequestId = null;

      // Initialiser le repository avec l'userId pour isoler les conversations
      await adhaRepository.init(userId: event.userId);

      emit(const AdhaInitial());
      debugPrint('[AdhaBloc] ‚úÖ Repository initialis√© pour l\'utilisateur');
    } catch (e) {
      debugPrint('[AdhaBloc] ‚ùå Erreur lors de l\'initialisation: $e');
      emit(AdhaError('Erreur d\'initialisation: $e'));
    }
  }

  @override
  Future<void> close() async {
    // Nettoyer les subscriptions audio
    await _audioConnectionSubscription?.cancel();
    await _audioLevelSubscription?.cancel();
    await _isRecordingSubscription?.cancel();
    await _isPlayingSubscription?.cancel();

    // Nettoyer les subscriptions de streaming
    await _streamChunkSubscription?.cancel();
    await _streamConnectionSubscription?.cancel();

    // Nettoyer les services
    _audioStreamingService.dispose();
    _streamService.dispose();

    // Fermer le repository
    await adhaRepository.close();

    return super.close();
  }
}
